import json
import os

import requests
import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages.chat import ChatMessage
from langchain_core.runnables import RunnablePassthrough

from utils.custom_logging import gemma_trace
from utils.prompts import load_prompt

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemma3 ì„¤ì •
GEMMA_URL = os.getenv("GEMMA_URL", "http://localhost:8000")  # ê¸°ë³¸ê°’ ì„¤ì •
MODELS = {
    "gemma3": "chat_model",  # Gemma3 ëª¨ë¸ëª…
}


def print_messages():
    """ì„¸ì…˜ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


def add_message(role, message):
    """ì„¸ì…˜ì— ìƒˆ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


def is_greeting(text: str) -> bool:
    """
    ë‹¨ìˆœ ì¸ì‚¬ë§(ì˜ˆ: "ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”")ë§Œì„ ì¸ì‹í•˜ë„ë¡ ê°œì„ í•©ë‹ˆë‹¤.
    """
    return text.strip() in {"ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”"}


def filter_conversation(history_msgs):
    """
    ëŒ€í™” ë‚´ì—­ì—ì„œ ì¸ì‚¬ë§, TIP, ì˜ˆì‹œ ì§ˆë¬¸ ë“± ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•©ë‹ˆë‹¤.
    """
    filtered = []
    exclusion_keywords = {
        "ì•ˆë…•",
        "ì•ˆë…•í•˜ì„¸ìš”",
        "TIP!",
        "ì˜ˆì‹œ ì§ˆë¬¸",
        "ë” ë‚˜ì€ ì‚¶ì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ë„ì‹œ",
    }
    for msg in history_msgs:
        if not any(msg.content.startswith(keyword) for keyword in exclusion_keywords):
            filtered.append(msg)
    return filtered


@gemma_trace(project_name="ebs-science")
def gemma_call(prompt: str) -> str:
    try:
        response = requests.post(
            f"{GEMMA_URL}/v1/chat/completions",
            json={
                "model": MODELS["gemma3"],
                "messages": [
                    {"role": "user", "content": [{"type": "text", "text": prompt}]}
                ],
                "max_tokens": 1000,
                "stream": True,
            },
            headers={
                "Authorization": f"Bearer {os.getenv('GEMMA_TOKEN')}",
                "Content-Type": "application/json",
            },
            stream=True,
        )
        response.raise_for_status()

        full_response = ""
        response_container = st.empty()

        for line in response.iter_lines():
            if line:
                try:
                    line_text = line.decode("utf-8")
                    if line_text.startswith("data: "):
                        line_text = line_text[6:]  # 'data: ' ì œê±°
                        if line_text.strip() == "[DONE]":
                            break  # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
                        try:
                            json_response = json.loads(line_text)
                            if (
                                json_response.get("choices")
                                and len(json_response["choices"]) > 0
                            ):
                                delta = json_response["choices"][0].get("delta", {})
                                if delta.get("content"):
                                    full_response += delta["content"]
                                    response_container.markdown(full_response + "â–Œ")
                        except json.JSONDecodeError:
                            continue  # JSON íŒŒì‹± ì‹¤íŒ¨í•œ ë¼ì¸ì€ ë¬´ì‹œ
                except UnicodeDecodeError:
                    continue  # ë””ì½”ë”© ì‹¤íŒ¨í•œ ë¼ì¸ì€ ë¬´ì‹œ

        response_container.markdown(full_response)
        return full_response

    except Exception as e:
        st.error(f"Gemma3 API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ íŠ¸ë ˆì´ì‹±ì—ì„œ ìº¡ì²˜í•  ìˆ˜ ìˆë„ë¡ í•¨


def create_chain(model_name=MODELS["gemma3"]):
    """
    í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•œ í›„, Gemma3 APIë¥¼ ì‚¬ìš©í•˜ëŠ” ì²´ì¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    prompt = load_prompt("prompts/yongin.yaml")
    chain = {"question": RunnablePassthrough()} | prompt | gemma_call
    return chain


def rewrite_query(user_question: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ìš©ì¸ì‹œì²­ ê´€ë ¨ ìµœì‹  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    rewriter_prompt = (
        "ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ìš©ì¸ì‹œì²­ ê´€ë ¨ ìµœì‹  ì •ë³´(ì •ì±…, ì„œë¹„ìŠ¤, í–‰ì‚¬ ë“±)ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” "
        "í•µì‹¬ í‚¤ì›Œë“œì™€ ë¬¸ì¥ì„ í¬í•¨í•œ ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ë‹µë³€ì€ ê°„ê²°í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        f"ì§ˆë¬¸: {user_question}\n"
        "ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬:"
    )
    rewritten = gemma_call(rewriter_prompt)
    return rewritten.strip()


def summarize_conversation(history_text: str) -> str:
    """
    ì£¼ì–´ì§„ ëŒ€í™” ë‚´ì—­ì„ ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    summary_prompt = (
        f"ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•´ì¤˜:\n\n{history_text}\n\nê°„ë‹¨í•˜ê²Œ ìš”ì•½í•´ì¤˜."
    )
    return gemma_call(summary_prompt).strip()


def detect_language(text: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ì „ì²´ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬, í•´ë‹¹ ì–¸ì–´ì˜ ISO 639-1 ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    prompt = (
        "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì „ì²´ ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬, í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ ì–´ë–¤ ì–¸ì–´ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ ISO 639-1 ì½”ë“œë¡œ í•œ ë‹¨ì–´ë¡œ ì‘ë‹µí•´ ì£¼ì„¸ìš”. "
        "ì˜ˆì‹œ: 'ko' (í•œêµ­ì–´), 'en' (ì˜ì–´), 'ja' (ì¼ë³¸ì–´).\n"
        f"í…ìŠ¤íŠ¸: '''{text}'''"
    )
    lang = gemma_call(prompt).strip()
    if lang not in {"ko", "en", "ja"}:
        lang = "ko"
    return lang


def translate_text(text: str, target_lang: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ target_lang ì–¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
    """
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ '{target_lang}'ë¡œ ë²ˆì—­í•´ì¤˜:\n{text}"
    return gemma_call(prompt).strip()


def summarize_sources(results):
    """
    ê²€ìƒ‰ëœ ê²°ê³¼ ì¤‘ ìµœëŒ€ 3ê°œì˜ ì¶œì²˜ ê¸°ë°˜ ì •ë³´ë¥¼ ìš”ì•½í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    summarized_text = []
    for r in results[:3]:
        chunk_text = r.get("chunk_text", "ë‚´ìš© ì—†ìŒ")
        doc_url = r.get("original_doc", {}).get("url", "ì¶œì²˜ ì—†ìŒ")
        summarized_text.append(f"- {chunk_text} (ì¶œì²˜: {doc_url})")
    return "\n".join(summarized_text)


def get_context_text(results):
    """
    ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ì§€ í‰ê°€í•˜ì—¬,
    ì¶©ë¶„í•˜ë©´ ì¶œì²˜ ê¸°ë°˜ ì •ë³´ë¥¼ ë°˜í™˜í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if results and len(results) > 0:
        summarized = summarize_sources(results)
        # ì˜ˆì‹œ: ìš”ì•½ëœ ê²°ê³¼ê°€ 50ì ë¯¸ë§Œì´ê±°ë‚˜ "ë‚´ìš© ì—†ìŒ"ì´ í¬í•¨ë˜ë©´ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨
        if len(summarized) < 50 or "ë‚´ìš© ì—†ìŒ" in summarized:
            return None
        return f"ğŸ“Œ **ì¶œì²˜ ê¸°ë°˜ ì •ë³´**\n{summarized}"
    return None

import logging
import os
import uuid

import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI

from services.ebs import EbsRAG
from services.pdf_viewer import PDFViewer
from utils.greeting_message import GREETING_MESSAGE
from utils.prompts import load_prompt

ebs_rag = EbsRAG()

# ì´ˆê¸° ë·°ì–´ ì œê±° (ê¸°ì¡´ pdf = PDFViewer(...) ë¶€ë¶„ ì‚­ì œ)

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown(
    """
<style>
.stMain { position: relative; }
.stChatMessage { background-color: transparent !important; }
.st-emotion-cache-glsyku { align-items: center; }
[data-testid="stChatMessage"]:has(> [data-testid="stChatMessageAvatarUser"]) {
    justify-content: flex-end !important;
    display: flex !important;
}
[data-testid="stChatMessage"]:has(> [data-testid="stChatMessageAvatarUser"]) [data-testid="stChatMessageContent"] {
    text-align: right !important;
    background-color: #3399FF !important;
    color: #FFFFFF !important;
    border-radius: 10px !important;
    padding: 10px !important;
    margin: 5px 0 !important;
    max-width: 80% !important;
    flex-grow: 0 !important;
}
</style>
""",
    unsafe_allow_html=True,
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(role="assistant", content=GREETING_MESSAGE["ebs_tutor"])
    ]
if "pdf_viewer_state" not in st.session_state:
    st.session_state["pdf_viewer_state"] = {"current_page": None}
if "search_results" not in st.session_state:
    st.session_state["search_results"] = None
if "questions" not in st.session_state:
    st.session_state["questions"] = {}  # ì§ˆë¬¸ ëª©ë¡ ì´ˆê¸°í™”
if "sources" not in st.session_state:
    st.session_state["sources"] = {}  # ì°¸ê³  í˜ì´ì§€ ì •ë³´ë¥¼ ì €ì¥í•  í‚¤
if "modal_open" not in st.session_state:
    st.session_state["modal_open"] = False  # ëª¨ë‹¬ ì—´ë¦¼ ìƒíƒœ
if "pdf_viewer" not in st.session_state:
    st.session_state["pdf_viewer"] = None  # PDF ë·°ì–´ ìƒíƒœ ì €ì¥ìš©


# ì•± ë©”ì¸ ë¶€ë¶„
st.title("EBS ê³¼í•™ íŠœí„° ì±—ë´‡")

# ì´ì „ ëŒ€í™” ë©”ì‹œì§€(ì¸ì‚¬ë§ í¬í•¨) í‘œì‹œ
for message in st.session_state["messages"]:
    st.chat_message(message.role).write(message.content)


# ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ í•¨ìˆ˜ ì¶”ê°€
def filter_results(results):
    return [
        r
        for r in results
        if r.get("score", 0) >= 0.5 and len(r.get("content", "").strip()) > 30
    ]


if user_input := st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!", key="chat_input"):
    question_id = str(uuid.uuid4())  # ê³ ìœ í•œ ì§ˆë¬¸ ID ìƒì„±
    st.chat_message("user").write(user_input)
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))
    st.session_state["questions"][question_id] = user_input

    try:
        results = ebs_rag.search(user_input, top_k=3)
        st.session_state["search_results"] = results

        if results:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_chunks = []
            sources = []
            for r in results:
                page_no = r.get("page_no")
                content = r.get("content")
                if page_no and content:
                    context_chunks.append(f"[{page_no}í˜ì´ì§€]\n{content}")
                    sources.append(f"{page_no}í˜ì´ì§€")
            context_text = "\n\n".join(context_chunks)
            if context_chunks:
                st.session_state["pdf_viewer_state"]["current_page"] = results[0][
                    "page_no"
                ]
        else:
            context_text = "ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            sources = []
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        context_text = "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        sources = []

    prompt_template = load_prompt("prompts/ebs_tutor.yaml")
    formatted_prompt = prompt_template.format(
        context_text=context_text, question=user_input
    )

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, streaming=True)
    response_generator = llm.stream(formatted_prompt)
    response_text = ""

    with st.chat_message("assistant"):
        response_container = st.empty()
        for chunk in response_generator:
            chunk_text = getattr(chunk, "content", str(chunk))
            response_text += chunk_text
            response_container.markdown(response_text)

    st.session_state["messages"].append(
        ChatMessage(role="assistant", content=response_text)
    )
    st.session_state["sources"][question_id] = sources
    st.session_state["pdf_viewer_state"]["current_page"] = (
        results[0]["page_no"] if results else None
    )


# @st.dialog("ì°¸ê³  í˜ì´ì§€ ë‚´ìš©")
# def pdf_viewer_modal(page_no):
#     """PDF ë·°ì–´ ëª¨ë‹¬ ëŒ€í™”ìƒì"""
#     pdf_path = "cache/pdf_pages/ë‰´ëŸ°ê³¼í•™1_ë¯¸ë‹ˆë¶"

#     # PDF ë·°ì–´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
#     pdf_viewer = PDFViewer(pdf_path)

#     # ëª¨ë‹¬ ì—´ë¦´ ë•Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
#     if "modal_open_time" not in st.session_state:
#         st.session_state.modal_open_time = True
#         # ëª¨ë‹¬ìš© í˜ì´ì§€ ìƒíƒœ ì´ˆê¸°í™”
#         if "modal_pdf_page" in st.session_state:
#             del st.session_state["modal_pdf_page"]

#     # ëª¨ë‹¬ ì „ìš© ë Œë”ë§ í•¨ìˆ˜ í˜¸ì¶œ
#     pdf_viewer.render_(initial_page=page_no)

#     # ëª¨ë‹¬ì´ ë‹«í ë•Œ ìƒíƒœ ì •ë¦¬ë¥¼ ìœ„í•œ ì¤€ë¹„
#     if "modal_open_time" in st.session_state:
#         del st.session_state.modal_open_time


@st.dialog("ì°¸ê³  í˜ì´ì§€ ë‚´ìš©")
def pdf_viewer_modal(initial_page):
    # ëª¨ë‹¬ì´ ì²˜ìŒ ì—´ë¦´ ë•Œ ì´ˆê¸° í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    if "modal_pdf_page" not in st.session_state:
        st.session_state.modal_pdf_page = initial_page

    current_page = st.session_state.modal_pdf_page

    # PDF í˜ì´ì§€ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    image_dir = "cache/pdf_pages/ë‰´ëŸ°ê³¼í•™1_ë¯¸ë‹ˆë¶"
    pdf_viewer = PDFViewer(image_dir)

    # PDFViewerì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ê³¼ ì´ í˜ì´ì§€ ìˆ˜ê°€ ì´ë¯¸ ê³„ì‚°ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    total_pages = pdf_viewer.total_pages  # PDFViewer ë‚´ë¶€ì—ì„œ ë¯¸ë¦¬ ìºì‹±ë˜ì–´ ìˆë‹¤ê³  ê°€ì •

    # ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
    image_container = st.empty()
    # info_container = st.empty()

    def update_view(page):
        # í˜„ì¬ í˜ì´ì§€ ì´ë¯¸ì§€ ê²½ë¡œ êµ¬ì„± (ë¦¬ìŠ¤íŠ¸ëŠ” 0-indexed)
        current_image_path = os.path.join(
            pdf_viewer.image_dir, pdf_viewer.image_files[page - 1]
        )
        image_container.image(current_image_path)
        # info_container.write(f"í˜ì´ì§€ {page} / {total_pages}")

    # ìµœì´ˆ ë Œë”ë§
    update_view(current_page)

    # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ: ì´ì „/ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ 3ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
    col_prev, col_dummy, col_next = st.columns([1, 2, 1])
    with col_prev:
        if st.button("ì´ì „ í˜ì´ì§€", key="modal_prev"):
            if current_page > 1:
                st.session_state.modal_pdf_page = current_page - 1
                update_view(st.session_state.modal_pdf_page)
    with col_next:
        if st.button("ë‹¤ìŒ í˜ì´ì§€", key="modal_next"):
            if current_page < total_pages:
                st.session_state.modal_pdf_page = current_page + 1
                update_view(st.session_state.modal_pdf_page)


# PDF í˜ì´ì§€ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
image_dir = "cache/pdf_pages/ë‰´ëŸ°ê³¼í•™1_ë¯¸ë‹ˆë¶"
pdf_viewer = PDFViewer(image_dir)
# ëª¨ë‹¬ì„ ì—´ ë•Œ íŠ¹ì • í˜ì´ì§€(ì˜ˆ: 3í˜ì´ì§€)ë¥¼ ì „ë‹¬
# if st.button("ëª¨ë‹¬ ì—´ê¸° (3í˜ì´ì§€)"):
#     # st.dialogë‚˜ st.modalì„ ì‚¬ìš©í•´ì„œ ëª¨ë‹¬ ì°½ì„ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#     pdf_viewer_modal(3)


# ì‚¬ì´ë“œë°” í‘œì‹œ
with st.sidebar:
    st.write("## ğŸ“Œ ì§ˆë¬¸ ëª©ë¡ ë° ì°¸ê³  í˜ì´ì§€")
    if "sources" in st.session_state and "questions" in st.session_state:
        for q_id, source_list in st.session_state["sources"].items():
            if q_id in st.session_state["questions"]:
                question_text = st.session_state["questions"][q_id]
                with st.expander(
                    f"ğŸ’¬ {len(question_text) > 30 and question_text[:30] + '...' or question_text}"
                ):
                    st.write(
                        f"ğŸ“ ì°¸ê³  í˜ì´ì§€:\n{', '.join([source.replace('í˜ì´ì§€', 'p') for source in source_list])}"
                    )
                    if st.button("ğŸ“– êµì¬ ë³´ê¸°", key=f"show_reference_page_{q_id}"):
                        # ëª¨ë‹¬ ì—´ë¦¼ ìƒíƒœë¥¼ ê´€ë¦¬
                        if st.session_state.get("modal_open", False):
                            st.warning("ì´ë¯¸ ëª¨ë‹¬ì´ ì—´ë ¤ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë‹«ì•„ì£¼ì„¸ìš”.")
                        else:
                            st.session_state["modal_open"] = True
                            current_page = st.session_state["pdf_viewer_state"].get(
                                "current_page", None
                            )
                            if current_page is not None:
                                try:
                                    # í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                                    page_no = int(current_page)
                                    pdf_viewer_modal(page_no)
                                except ValueError:
                                    st.error(
                                        f"ìœ íš¨í•˜ì§€ ì•Šì€ í˜ì´ì§€ ë²ˆí˜¸: {current_page}"
                                    )
                            # ëª¨ë‹¬ì´ ë‹«íˆë©´(í•¨ìˆ˜ ì‹¤í–‰ì´ ëë‚˜ë©´) ìƒíƒœ ì´ˆê¸°í™”
                            st.session_state["modal_open"] = False

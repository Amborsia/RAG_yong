import logging
import os
import uuid

import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI

from services.ebs import EbsRAG
from services.pdf_viewer import PDFViewer
from utils.greeting_message import GREETING_MESSAGE
from utils.prompts import load_prompt

ebs_rag = EbsRAG()

# ì´ˆê¸° ë·°ì–´ ì œê±° (ê¸°ì¡´ pdf = PDFViewer(...) ë¶€ë¶„ ì‚­ì œ)

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown(
    """
<style>
.stMain { position: relative; }
.stChatMessage { background-color: transparent !important; }
.st-emotion-cache-glsyku { align-items: center; }
[data-testid="stChatMessage"]:has(> [data-testid="stChatMessageAvatarUser"]) {
    justify-content: flex-end !important;
    display: flex !important;
}
[data-testid="stChatMessage"]:has(> [data-testid="stChatMessageAvatarUser"]) [data-testid="stChatMessageContent"] {
    text-align: right !important;
    background-color: #3399FF !important;
    color: #FFFFFF !important;
    border-radius: 10px !important;
    padding: 10px !important;
    margin: 5px 0 !important;
    max-width: 80% !important;
    flex-grow: 0 !important;
}
</style>
""",
    unsafe_allow_html=True,
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(role="assistant", content=GREETING_MESSAGE["ebs_tutor"])
    ]
if "pdf_viewer_state" not in st.session_state:
    st.session_state["pdf_viewer_state"] = {"current_page": None}
if "search_results" not in st.session_state:
    st.session_state["search_results"] = None
if "questions" not in st.session_state:
    st.session_state["questions"] = {}  # ì§ˆë¬¸ ëª©ë¡ ì´ˆê¸°í™”
if "sources" not in st.session_state:
    st.session_state["sources"] = {}  # ì°¸ê³  í˜ì´ì§€ ì •ë³´ë¥¼ ì €ì¥í•  í‚¤
if "modal_open" not in st.session_state:
    st.session_state["modal_open"] = False  # ëª¨ë‹¬ ì—´ë¦¼ ìƒíƒœ
if "pdf_viewer" not in st.session_state:
    st.session_state["pdf_viewer"] = None  # PDF ë·°ì–´ ìƒíƒœ ì €ì¥ìš©


# ì•± ë©”ì¸ ë¶€ë¶„
st.title("EBS ê³¼í•™ íŠœí„° ì±—ë´‡")

# ì´ì „ ëŒ€í™” ë©”ì‹œì§€(ì¸ì‚¬ë§ í¬í•¨) í‘œì‹œ
for message in st.session_state["messages"]:
    st.chat_message(message.role).write(message.content)


# ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ í•¨ìˆ˜ ì¶”ê°€
def filter_results(results):
    return [
        r
        for r in results
        if r.get("score", 0) >= 0.5 and len(r.get("content", "").strip()) > 30
    ]


if user_input := st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!", key="chat_input"):
    question_id = str(uuid.uuid4())  # ê³ ìœ í•œ ì§ˆë¬¸ ID ìƒì„±
    st.chat_message("user").write(user_input)
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))
    st.session_state["questions"][question_id] = user_input

    try:
        results = ebs_rag.search(user_input, top_k=3)
        st.session_state["search_results"] = results

        if results:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_chunks = []
            sources = []
            for r in results:
                page_no = r.get("page_no")
                content = r.get("content")
                if page_no and content:
                    context_chunks.append(f"[{page_no}í˜ì´ì§€]\n{content}")
                    sources.append(f"{page_no}í˜ì´ì§€")
            context_text = "\n\n".join(context_chunks)
            if context_chunks:
                st.session_state["pdf_viewer_state"]["current_page"] = results[0][
                    "page_no"
                ]
        else:
            context_text = "ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            sources = []
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        context_text = "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        sources = []

    prompt_template = load_prompt("prompts/ebs_tutor.yaml")
    formatted_prompt = prompt_template.format(
        context_text=context_text, question=user_input
    )

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, streaming=True)
    response_generator = llm.stream(formatted_prompt)
    response_text = ""

    with st.chat_message("assistant"):
        response_container = st.empty()
        for chunk in response_generator:
            chunk_text = getattr(chunk, "content", str(chunk))
            response_text += chunk_text
            response_container.markdown(response_text)

    st.session_state["messages"].append(
        ChatMessage(role="assistant", content=response_text)
    )
    st.session_state["sources"][question_id] = sources
    st.session_state["pdf_viewer_state"]["current_page"] = (
        results[0]["page_no"] if results else None
    )


@st.dialog("ì°¸ê³  í˜ì´ì§€ ë‚´ìš©")
def pdf_viewer_modal(initial_page):
    # ëª¨ë‹¬ ì „ìš© í˜ì´ì§€ ë²ˆí˜¸ê°€ ì„¸ì…˜ì— ì—†ë‹¤ë©´ ì •ìˆ˜í˜•ìœ¼ë¡œ ì´ˆê¸°í™”
    if "modal_current_page" not in st.session_state:
        st.session_state["modal_current_page"] = int(initial_page)

    image_dir = "cache/pdf_pages/ë‰´ëŸ°ê³¼í•™1_ë¯¸ë‹ˆë¶"
    pdf_viewer = PDFViewer(image_dir)
    current_page = int(st.session_state["modal_current_page"])
    total_pages = pdf_viewer.total_pages  # PDFViewerê°€ ì´ í˜ì´ì§€ ìˆ˜ë¥¼ ê³„ì‚°í–ˆë‹¤ê³  ê°€ì •

    image_container = st.empty()

    def update_view():
        cp = int(st.session_state["modal_current_page"])
        current_image_path = os.path.join(
            pdf_viewer.image_dir, pdf_viewer.image_files[cp - 1]
        )
        image_container.image(current_image_path, width=600)  # ê³ ì • í¬ê¸°ë¡œ í‘œì‹œ
        # st.write(f"í˜ì´ì§€ {cp} / {total_pages}")

    update_view()

    col_prev, col_dummy, col_next = st.columns([1, 2, 1])
    with col_prev:
        if st.button("ì´ì „ í˜ì´ì§€", key="modal_prev"):
            if int(st.session_state["modal_current_page"]) > 1:
                st.session_state["modal_current_page"] = (
                    int(st.session_state["modal_current_page"]) - 1
                )
                update_view()
    with col_next:
        if st.button("ë‹¤ìŒ í˜ì´ì§€", key="modal_next"):
            if int(st.session_state["modal_current_page"]) < total_pages:
                st.session_state["modal_current_page"] = (
                    int(st.session_state["modal_current_page"]) + 1
                )
                update_view()


# PDF í˜ì´ì§€ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
image_dir = "cache/pdf_pages/ë‰´ëŸ°ê³¼í•™1_ë¯¸ë‹ˆë¶"
pdf_viewer = PDFViewer(image_dir)
# ëª¨ë‹¬ì„ ì—´ ë•Œ íŠ¹ì • í˜ì´ì§€(ì˜ˆ: 3í˜ì´ì§€)ë¥¼ ì „ë‹¬
# if st.button("ëª¨ë‹¬ ì—´ê¸° (3í˜ì´ì§€)"):
#     # st.dialogë‚˜ st.modalì„ ì‚¬ìš©í•´ì„œ ëª¨ë‹¬ ì°½ì„ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#     pdf_viewer_modal(3)


# ì‚¬ì´ë“œë°” í‘œì‹œ
# ì‚¬ì´ë“œë°”ì—ì„œ "êµì¬ ë³´ê¸°" ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œ, ëª¨ë‹¬ ì „ìš© í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
with st.sidebar:
    st.write("## ğŸ“Œ ì§ˆë¬¸ ëª©ë¡ ë° ì°¸ê³  í˜ì´ì§€")
    if "sources" in st.session_state and "questions" in st.session_state:
        for q_id, source_list in st.session_state["sources"].items():
            if q_id in st.session_state["questions"]:
                question_text = st.session_state["questions"][q_id]
                with st.expander(
                    f"ğŸ’¬ {len(question_text) > 30 and question_text[:30] + '...' or question_text}"
                ):
                    st.write(
                        f"ğŸ“ ì°¸ê³  í˜ì´ì§€:\n{', '.join([source.replace('í˜ì´ì§€', 'p') for source in source_list])}"
                    )
                    if st.button("ğŸ“– êµì¬ ë³´ê¸°", key=f"show_reference_page_{q_id}"):
                        # ìƒˆ ëª¨ë‹¬ì„ ì—´ ë•Œ, í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¼ ì´ˆê¸° í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì¬ì„¤ì •
                        initial_page = st.session_state["pdf_viewer_state"].get(
                            "current_page", 1
                        )
                        st.session_state["modal_current_page"] = (
                            initial_page  # ëª¨ë‹¬ ì „ìš© ìƒíƒœ ì´ˆê¸°í™”
                        )
                        pdf_viewer_modal(initial_page)
